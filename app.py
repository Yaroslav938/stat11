import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import plotly.figure_factory as ff
from scipy import stats
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import itertools
import warnings
import io

# –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
warnings.filterwarnings("ignore")

st.set_page_config(page_title="üî¨ StatPack OmniLab v14", layout="wide", page_icon="üìà")

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –ë–õ–û–ö 1: –î–í–ò–ñ–ö–ò –ü–ê–†–°–ò–ù–ì–ê –ò –£–¢–ò–õ–ò–¢–´ –≠–ö–°–ü–û–†–¢–ê
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

@st.cache_data
def convert_df_to_csv(df):
    return df.to_csv(index=False).encode('utf-8')

@st.cache_data
def convert_df_to_csv_with_index(df):
    return df.to_csv(index=True).encode('utf-8')

@st.cache_data
def convert_df_to_excel(df):
    """–≠–∫—Å–ø–æ—Ä—Ç DataFrame –≤ —Ñ–æ—Ä–º–∞—Ç Excel (.xlsx)"""
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='–°–≤–æ–¥–Ω–∞—è_—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞')
    return output.getvalue()

@st.cache_data
def smart_parse_headers(file, header_rows):
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä: —Å–∫–ª–µ–∏–≤–∞–µ—Ç –º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤—ã–µ —à–∞–ø–∫–∏"""
    try:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file, header=None)
        else:
            df = pd.read_excel(file, header=None)
            
        if header_rows > 0:
            headers = df.iloc[:header_rows].ffill(axis=1)
            new_cols = []
            for col_idx in range(headers.shape[1]):
                col_vals = headers.iloc[:, col_idx].values
                clean_vals = [str(v).strip() for v in col_vals if pd.notna(v) and str(v).lower() != 'nan']
                col_name = " | ".join(clean_vals) if clean_vals else f"–°—Ç–æ–ª–±–µ—Ü_{col_idx}"
                new_cols.append(col_name)
            
            df.columns = new_cols
            df = df.iloc[header_rows:].reset_index(drop=True)
            
        return df
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")
        return None

@st.cache_data
def parse_rnf_special(file, n_simulations=10):
    """–°–ø–µ—Ü-–ø–∞—Ä—Å–µ—Ä: –¥–ª—è —Ç–∞–±–ª–∏—Ü, –≥–¥–µ –¥–∞–Ω—ã —Ç–æ–ª—å–∫–æ min –∏ max –∑–Ω–∞—á–µ–Ω–∏—è"""
    try:
        if file.name.endswith('.csv'):
            df = pd.read_csv(file, header=None)
        else:
            df = pd.read_excel(file, header=None)

        min_max_row_idx = None
        for idx, row in df.iterrows():
            row_str = [str(val).lower().strip() for val in row.values]
            if 'min' in row_str and 'max' in row_str:
                min_max_row_idx = idx
                break

        if min_max_row_idx is not None:
            features_raw = df.iloc[min_max_row_idx - 1].values
            
            current_feature = "Unknown"
            feature_map = []
            for p in features_raw:
                p_str = str(p).strip()
                if pd.notna(p) and p_str != "" and p_str.lower() != "nan" and "–∑–æ–Ω–∞" not in p_str.lower():
                    current_feature = p_str
                feature_map.append(current_feature)

            data_rows = df.iloc[min_max_row_idx + 1:]
            parsed_data = []

            for _, row in data_rows.iterrows():
                object_name = row.iloc[0]
                if pd.isna(object_name) or str(object_name).strip() == "":
                    continue

                for col_idx in range(1, len(row)):
                    col_type = str(df.iloc[min_max_row_idx, col_idx]).lower().strip()
                    if col_type in ['min', 'max']:
                        val = pd.to_numeric(row.iloc[col_idx], errors='coerce')
                        if pd.notna(val):
                            parsed_data.append({
                                "ID": str(object_name).strip(),
                                "–ü—Ä–∏–∑–Ω–∞–∫": feature_map[col_idx],
                                "–¢–∏–ø": col_type,
                                "–ó–Ω–∞—á–µ–Ω–∏–µ": val
                            })

            long_df = pd.DataFrame(parsed_data)
            if long_df.empty: return None, None
                
            pivot_df = long_df.pivot_table(index=['ID', '–ü—Ä–∏–∑–Ω–∞–∫'], columns='–¢–∏–ø', values='–ó–Ω–∞—á–µ–Ω–∏–µ').reset_index()
            pivot_df['Mid'] = (pivot_df['min'] + pivot_df['max']) / 2
            
            simulated = []
            for _, row in pivot_df.dropna().iterrows():
                if row['min'] == row['max']:
                    vals = np.full(n_simulations, row['min'])
                else:
                    vals = np.random.uniform(row['min'], row['max'], n_simulations)
                for v in vals:
                    simulated.append({"ID": row['ID'], "–ü—Ä–∏–∑–Ω–∞–∫": row['–ü—Ä–∏–∑–Ω–∞–∫'], "–ó–Ω–∞—á–µ–Ω–∏–µ": v})
                    
            sim_df = pd.DataFrame(simulated)
            wide_df = pivot_df.pivot_table(index="ID", columns="–ü—Ä–∏–∑–Ω–∞–∫", values="Mid").fillna(0)
            return wide_df, sim_df
        return None, None
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å–ø–µ—Ü-—Ñ–æ—Ä–º–∞—Ç–∞: {e}")
        return None, None

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –ë–õ–û–ö 2: –ú–ê–¢–ï–ú–ê–¢–ò–ö–ê –ò –°–¢–ê–¢–ò–°–¢–ò–ö–ê
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def cohens_d(x, y):
    """–†–∞—Å—á–µ—Ç —Ä–∞–∑–º–µ—Ä–∞ —ç—Ñ—Ñ–µ–∫—Ç–∞ (Cohen's d) —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –¥–µ–ª–µ–Ω–∏—è –Ω–∞ 0"""
    nx, ny = len(x), len(y)
    dof = nx + ny - 2
    if dof <= 0: return 0
    poolsd = np.sqrt(((nx-1)*np.var(x, ddof=1) + (ny-1)*np.var(y, ddof=1)) / dof)
    if poolsd == 0: return 0
    return (np.mean(x) - np.mean(y)) / poolsd

def perform_pairwise_tests(df, group_col, val_col, parametric=False):
    """Post-Hoc —Ç–µ—Å—Ç—ã —Å –ø–æ–ø—Ä–∞–≤–∫–æ–π –ë–æ–Ω—Ñ–µ—Ä—Ä–æ–Ω–∏ –∏ Cohen's d"""
    groups = df[group_col].unique()
    results = []
    
    for g1, g2 in itertools.combinations(groups, 2):
        d1 = df[df[group_col] == g1][val_col].dropna().values
        d2 = df[df[group_col] == g2][val_col].dropna().values
        
        if len(d1) < 2 or len(d2) < 2: continue
            
        if np.var(d1) == 0 and np.var(d2) == 0 and np.mean(d1) == np.mean(d2):
            p = 1.0
        else:
            if parametric:
                stat, p = stats.ttest_ind(d1, d2, equal_var=False)
            else:
                stat, p = stats.mannwhitneyu(d1, d2, alternative='two-sided')
            
        effect_size = abs(cohens_d(d1, d2))
        
        if effect_size >= 0.8: eff_str = "–í—ã—Å–æ–∫–∏–π"
        elif effect_size >= 0.5: eff_str = "–°—Ä–µ–¥–Ω–∏–π"
        elif effect_size >= 0.2: eff_str = "–ú–∞–ª—ã–π"
        else: eff_str = "–ù–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π"
            
        results.append((g1, g2, p, effect_size, eff_str))
        
    if not results: return pd.DataFrame()
        
    res_df = pd.DataFrame(results, columns=['–ì—Ä—É–ø–ø–∞ 1', '–ì—Ä—É–ø–ø–∞ 2', 'p_raw', "Cohen's d", "–≠—Ñ—Ñ–µ–∫—Ç"])
    n_tests = len(res_df)
    res_df['p_adj (Bonf)'] = (res_df['p_raw'] * n_tests).clip(upper=1.0)
    
    return res_df[['–ì—Ä—É–ø–ø–∞ 1', '–ì—Ä—É–ø–ø–∞ 2', 'p_adj (Bonf)', "Cohen's d", "–≠—Ñ—Ñ–µ–∫—Ç"]]

def calc_mode(series):
    """–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –º–æ–¥—ã –≤ pandas groupby"""
    m = series.mode()
    return m.iloc[0] if not m.empty else np.nan

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –ò–ù–¢–ï–†–§–ï–ô–° –õ–ê–ë–û–†–ê–¢–û–†–ò–ò (UI)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

st.title("üìà StatPack OmniLab v14: Data Science Edition")
st.markdown("*–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –º—É–ª—å—Ç–∏-–∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è —Å—Ç–∞–Ω—Ü–∏—è –¥–ª—è –ª—é–±—ã—Ö —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö (–ë–∏–æ–ª–æ–≥–∏—è, –•–∏–º–∏—è, –≠–∫–æ–Ω–æ–º–∏–∫–∞, –°–æ—Ü–∏–æ–ª–æ–≥–∏—è).*")

# ‚îÄ‚îÄ –ë–û–ö–û–í–ê–Ø –ü–ê–ù–ï–õ–¨ (–ù–ê–°–¢–†–û–ô–ö–ò) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
with st.sidebar:
    st.header("üìÇ 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
    uploaded_file = st.file_uploader("–§–∞–π–ª Excel / CSV", type=["csv", "xlsx"])
    
    st.markdown("---")
    st.header("‚öôÔ∏è 2. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞")
    parse_mode = st.selectbox(
        "–†–µ–∂–∏–º —á—Ç–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö:",
        ["–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π (–ü–ª–æ—Å–∫–∏–µ/–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ —à–∞–ø–∫–∏)", "–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å–∏–º—É–ª—è—Ü–∏–π (—Ç–æ–ª—å–∫–æ min/max)"],
        help="–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π - –¥–ª—è –ª—é–±—ã—Ö —Ç–∞–±–ª–∏—Ü. –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å–∏–º—É–ª—è—Ü–∏–π - –¥–ª—è —Ç–∞–±–ª–∏—Ü, –≥–¥–µ —É–∫–∞–∑–∞–Ω—ã –¥–∏–∞–ø–∞–∑–æ–Ω—ã –∑–Ω–∞—á–µ–Ω–∏–π –≤–º–µ—Å—Ç–æ —Å—ã—Ä—ã—Ö —Ç–æ—á–µ–∫."
    )
    
    if parse_mode == "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π (–ü–ª–æ—Å–∫–∏–µ/–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ —à–∞–ø–∫–∏)":
        header_rows = st.number_input("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –≤ —à–∞–ø–∫–µ (–¥–ª—è —Å–∫–ª–µ–π–∫–∏):", 1, 5, 1)
        n_simulations = 10
    else:
        n_simulations = st.slider("–¢–æ—á–µ–∫ —Å–∏–º—É–ª—è—Ü–∏–∏ (N)", 3, 30, 10)
        header_rows = 1
        
    st.markdown("---")
    st.header("üé® 3. –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏")
    alpha_level = st.selectbox("–£—Ä–æ–≤–µ–Ω—å –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ (Œ±):", [0.05, 0.01, 0.10], index=0)
    color_theme = st.selectbox("–¶–≤–µ—Ç–æ–≤–∞—è –ø–∞–ª–∏—Ç—Ä–∞:", ["Viridis", "Plasma", "Turbo", "Spectral", "RdBu_r", "Plotly3"], index=0)

# ‚îÄ‚îÄ –ü–û–î–ì–û–¢–û–í–ö–ê –ò –û–ß–ò–°–¢–ö–ê –î–ê–ù–ù–´–• ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
if uploaded_file:
    wide_df, long_df = None, None
    is_ready = False

    if parse_mode == "–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å–∏–º—É–ª—è—Ü–∏–π (—Ç–æ–ª—å–∫–æ min/max)":
        with st.spinner("–°–±–æ—Ä–∫–∞ –∏ —Å–∏–º—É–ª—è—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö..."):
            wide_df, long_df = parse_rnf_special(uploaded_file, n_simulations)
            if wide_df is not None:
                st.sidebar.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤: {len(wide_df)}")
                is_ready = True
            else:
                st.error("–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ '–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π' —Ä–µ–∂–∏–º.")

    elif parse_mode == "–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π (–ü–ª–æ—Å–∫–∏–µ/–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ —à–∞–ø–∫–∏)":
        raw_df = smart_parse_headers(uploaded_file, header_rows)
        if raw_df is not None:
            with st.expander("üõ† –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ (–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–æ–ª–±—Ü—ã)", expanded=True):
                st.dataframe(raw_df.head(3), use_container_width=True)
                col_id, col_features = st.columns([1, 2])
                
                with col_id:
                    id_col = st.selectbox("–£–∫–∞–∂–∏—Ç–µ —Å—Ç–æ–ª–±–µ—Ü —Å –æ–±—ä–µ–∫—Ç–∞–º–∏ (ID, –ù–∞–∑–≤–∞–Ω–∏—è, –ì—Ä—É–ø–ø—ã):", options=raw_df.columns, index=0)
                with col_features:
                    possible_features = [c for c in raw_df.columns if c != id_col]
                    feature_cols = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ) –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:", options=possible_features, default=possible_features)
                
                if id_col and feature_cols:
                    try:
                        clean_df = raw_df[[id_col] + feature_cols].copy()
                        clean_df.rename(columns={id_col: "ID"}, inplace=True)
                        for col in feature_cols:
                            clean_df[col] = pd.to_numeric(clean_df[col], errors='coerce')
                        
                        long_df = clean_df.melt(id_vars=["ID"], value_vars=feature_cols, var_name="–ü—Ä–∏–∑–Ω–∞–∫", value_name="–ó–Ω–∞—á–µ–Ω–∏–µ").dropna()
                        wide_df = clean_df.groupby("ID")[feature_cols].mean().fillna(0)
                        wide_df = wide_df.loc[:, (wide_df != 0).any(axis=0)] # –ß–∏—Å—Ç–∫–∞ —Å—Ç–æ–ª–±—Ü–æ–≤, –≥–¥–µ —Ç–æ–ª—å–∫–æ –Ω—É–ª–∏
                        st.sidebar.success(f"‚úÖ –ì–æ—Ç–æ–≤–æ: {len(wide_df)} –æ–±—ä–µ–∫—Ç–æ–≤")
                        is_ready = True
                    except Exception as e:
                        st.error(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö: {e}")

    # ‚îÄ‚îÄ –õ–ê–ë–û–†–ê–¢–û–†–ò–Ø (–í–ö–õ–ê–î–ö–ò) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    if is_ready and wide_df is not None and not wide_df.empty:
        st.markdown("---")
        t1, t2, t3, t4, t5, t6, t7 = st.tabs([
            "üìä 1. –û–ø–∏—Å–∞—Ç–µ–ª—å–Ω–∞—è (EDA)", 
            "üìà 2. –†–µ–≥—Ä–µ—Å—Å–∏—è", 
            "üå≥ 3. –ö–ª–∞—Å—Ç–µ—Ä—ã (PCA)", 
            "üî¨ 4. –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (ANOVA)", 
            "‚öñÔ∏è 5. A/B –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (t-—Ç–µ—Å—Ç—ã)",
            "üìë 6. –°–≤–æ–¥–Ω–∞—è –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞",
            "üóÑ 7. –≠–∫—Å–ø–æ—Ä—Ç"
        ])

        # ‚îÄ‚îÄ –í–ö–õ–ê–î–ö–ê 1. EDA ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        with t1:
            st.markdown("### –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π –∏ –ø—Ä–æ—Ñ–∏–ª–µ–π")
            
            c1, c2 = st.columns([1.5, 1])
            with c1:
                # Heatmap
                fig_heat = px.imshow(wide_df, color_continuous_scale=color_theme, aspect="auto",
                                     title="–¢–µ–ø–ª–æ–≤–∞—è –º–∞—Ç—Ä–∏—Ü–∞ —Å—Ä–µ–¥–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π")
                st.plotly_chart(fig_heat, use_container_width=True)
            with c2:
                # –†–∞–¥–∞—Ä
                sel_ids = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ –æ–±—ä–µ–∫—Ç—ã –¥–ª—è –†–∞–¥–∞—Ä–∞:", options=wide_df.index.tolist(),
                                         default=wide_df.index.tolist()[:3] if len(wide_df)>=3 else wide_df.index.tolist())
                if sel_ids and len(wide_df.columns) >= 3:
                    fig_radar = go.Figure()
                    for s_id in sel_ids:
                        vals = wide_df.loc[s_id].values.tolist()
                        fig_radar.add_trace(go.Scatterpolar(r=vals+[vals[0]], theta=wide_df.columns.tolist()+[wide_df.columns[0]], fill='toself', name=str(s_id)))
                    fig_radar.update_layout(polar=dict(radialaxis=dict(visible=True)), title="–ú–Ω–æ–≥–æ–º–µ—Ä–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ (Spider Chart)")
                    st.plotly_chart(fig_radar, use_container_width=True)
                else:
                    st.info("–î–ª—è —Ä–∞–¥–∞—Ä–∞ –Ω—É–∂–Ω–æ ‚â•3 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.")

            st.markdown("---")
            # –°—Ç–æ–ª–±—á–∞—Ç—ã–µ –¥–∏–∞–≥—Ä–∞–º–º—ã (Bar Charts) —Å –ø–ª–∞–Ω–∫–∞–º–∏ –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç–µ–π
            st.markdown("#### –°—Ç–æ–ª–±—á–∞—Ç–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞ (–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å –ø–ª–∞–Ω–∫–∞–º–∏ –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç–µ–π SD)")
            bar_df = long_df.groupby(["ID", "–ü—Ä–∏–∑–Ω–∞–∫"])["–ó–Ω–∞—á–µ–Ω–∏–µ"].agg(['mean', 'std']).reset_index()
            bar_df['std'] = bar_df['std'].fillna(0) # –ó–∞—â–∏—Ç–∞ –æ—Ç –µ–¥–∏–Ω–∏—á–Ω—ã—Ö —Ä–µ–ø–ª–∏–∫
            
            fig_bar = px.bar(bar_df, x="ID", y="mean", color="–ü—Ä–∏–∑–Ω–∞–∫", barmode="group",
                             error_y="std", title="–°—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (—Å –ø–ª–∞–Ω–∫–∞–º–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è)",
                             labels={"mean": "–°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ", "ID": "–û–±—ä–µ–∫—Ç (–ì—Ä—É–ø–ø–∞)"})
            st.plotly_chart(fig_bar, use_container_width=True)

            st.markdown("---")
            # –°–∫—Ä–∏–ø–∏—á–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏
            st.markdown("#### –°–∫—Ä–∏–ø–∏—á–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ (Violin Plot) - –ê–Ω–∞–ª–∏–∑ –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏")
            st.caption("–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ñ–æ—Ä–º—É —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è, –º–µ–¥–∏–∞–Ω—É, –∫–≤–∞—Ä—Ç–∏–ª–∏ (–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –±–æ–∫—Å) –∏ –≤—Å–µ —Å—ã—Ä—ã–µ —Ç–æ—á–∫–∏ –≤—ã–±–æ—Ä–∫–∏.")
            fig_violin = px.violin(long_df, x="–ü—Ä–∏–∑–Ω–∞–∫", y="–ó–Ω–∞—á–µ–Ω–∏–µ", color="–ü—Ä–∏–∑–Ω–∞–∫", 
                                   box=True, points="all", hover_data=["ID"],
                                   title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π –ø–æ –≤—Å–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º")
            st.plotly_chart(fig_violin, use_container_width=True)


        # ‚îÄ‚îÄ –í–ö–õ–ê–î–ö–ê 2. –†–ï–ì–†–ï–°–°–ò–Ø –ò –ö–û–†–†–ï–õ–Ø–¶–ò–Ø ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        with t2:
            st.markdown("### –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∏ –†–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
            if len(wide_df.columns) > 1:
                c1, c2 = st.columns([1, 2])
                with c1:
                    fig_corr = px.imshow(wide_df.corr(), text_auto=".2f", color_continuous_scale=color_theme,
                                         title="–ö—Ä–∏—Ç–µ—Ä–∏–π –ü–∏—Ä—Å–æ–Ω–∞ (–ú–∞—Ç—Ä–∏—Ü–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π)")
                    st.plotly_chart(fig_corr, use_container_width=True)
                
                with c2:
                    st.markdown("#### –õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è (–ú–µ—Ç–æ–¥ –Ω–∞–∏–º–µ–Ω—å—à–∏—Ö –∫–≤–∞–¥—Ä–∞—Ç–æ–≤)")
                    st.caption("–û—Ü–µ–Ω–∫–∞ —Å—Ç–µ–ø–µ–Ω–∏ –ª–∏–Ω–µ–π–Ω–æ–π –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –º–µ–∂–¥—É –¥–≤—É–º—è –ª—é–±—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏.")
                    
                    reg_col1, reg_col2 = st.columns(2)
                    with reg_col1: x_feat = st.selectbox("–ù–µ–∑–∞–≤–∏—Å–∏–º–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è (–û—Å—å X):", wide_df.columns, index=0)
                    with reg_col2: y_feat = st.selectbox("–ó–∞–≤–∏—Å–∏–º–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è (–û—Å—å Y):", wide_df.columns, index=1 if len(wide_df.columns)>1 else 0)
                    
                    if x_feat != y_feat:
                        slope, intercept, r_value, p_value, std_err = stats.linregress(wide_df[x_feat], wide_df[y_feat])
                        r_squared = r_value**2
                        
                        fig_reg = px.scatter(wide_df.reset_index(), x=x_feat, y=y_feat, text="ID", 
                                             title=f"–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å: {y_feat} –æ—Ç {x_feat}", size_max=10)
                        fig_reg.update_traces(textposition='top center')
                        
                        x_range = np.linspace(wide_df[x_feat].min(), wide_df[x_feat].max(), 100)
                        y_range = slope * x_range + intercept
                        fig_reg.add_trace(go.Scatter(x=x_range, y=y_range, mode='lines', name='–õ–∏–Ω–∏—è OLS', line=dict(color='red', width=2)))
                        
                        st.plotly_chart(fig_reg, use_container_width=True)
                        
                        st.markdown(f"**–£—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä—è–º–æ–π:** `y = {slope:.3f} * x + {intercept:.3f}`")
                        m1, m2, m3 = st.columns(3)
                        m1.metric("R¬≤ (–ö–æ—ç—Ñ. –¥–µ—Ç–µ—Ä–º–∏–Ω–∞—Ü–∏–∏)", f"{r_squared:.3f}")
                        m2.metric("p-value (–ó–Ω–∞—á–∏–º–æ—Å—Ç—å —Ç—Ä–µ–Ω–¥–∞)", f"{p_value:.4e}")
                        m3.metric("–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –æ—à–∏–±–∫–∞", f"{std_err:.3f}")
                        
                        if p_value < alpha_level:
                            st.success(f"‚úÖ –í—ã—è–≤–ª–µ–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º–∞—è –ª–∏–Ω–µ–π–Ω–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å (p < {alpha_level})")
                        else:
                            st.warning(f"‚ö†Ô∏è –õ–∏–Ω–µ–π–Ω–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –Ω–µ–∑–Ω–∞—á–∏–º–∞ (p ‚â• {alpha_level})")
                    else:
                        st.info("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ —Ä–∞–∑–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è X –∏ Y.")
            else:
                st.warning("–î–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–≤—è–∑–µ–π —Ç—Ä–µ–±—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 2 –ø—Ä–∏–∑–Ω–∞–∫–∞.")


        # ‚îÄ‚îÄ –í–ö–õ–ê–î–ö–ê 3. PCA & TREES ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        with t3:
            st.markdown("### –ü–æ–∏—Å–∫ —Å–∫—Ä—ã—Ç—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏ –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è")
            if len(wide_df) >= 3 and len(wide_df.columns) >= 2:
                scaler = StandardScaler()
                X_scaled = scaler.fit_transform(wide_df)
                
                st.markdown("#### –ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è (–î–µ–Ω–¥—Ä–æ–≥—Ä–∞–º–º–∞ —Å—Ö–æ–¥—Å—Ç–≤–∞)")
                try:
                    fig_dendro = ff.create_dendrogram(X_scaled, labels=wide_df.index.tolist(), color_threshold=2.5)
                    fig_dendro.update_layout(height=450, margin=dict(b=100))
                    fig_dendro.update_xaxes(tickangle=45)
                    st.plotly_chart(fig_dendro, use_container_width=True)
                except Exception:
                    st.warning("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –¥–µ—Ä–µ–≤–∞.")

                st.markdown("---")
                st.markdown("#### –ú–µ—Ç–æ–¥ –≥–ª–∞–≤–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç (PCA Biplot)")
                pca_col1, pca_col2 = st.columns([1, 3])
                
                with pca_col1:
                    n_clusters = st.slider("–û–∂–∏–¥–∞–µ–º–æ–µ —á–∏—Å–ª–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ (KMeans):", 2, min(8, len(wide_df)-1), 3)
                    km = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
                    clusters = km.fit_predict(X_scaled).astype(str)
                    
                    pca = PCA(n_components=2)
                    pca_coords = pca.fit_transform(X_scaled)
                    loadings = pca.components_.T * np.sqrt(pca.explained_variance_)
                    
                    st.metric("–í–∫–ª–∞–¥ 1-–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (PC1)", f"{pca.explained_variance_ratio_[0]*100:.1f}%")
                    st.metric("–í–∫–ª–∞–¥ 2-–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (PC2)", f"{pca.explained_variance_ratio_[1]*100:.1f}%")
                    
                    pca_df = pd.DataFrame(pca_coords, columns=["PC1", "PC2"], index=wide_df.index)
                    pca_df["Cluster"] = clusters

                with pca_col2:
                    fig_pca = px.scatter(pca_df.reset_index(), x="PC1", y="PC2", color="Cluster", text="ID", size_max=15, height=600)
                    fig_pca.update_traces(textposition='top center', marker=dict(size=12, line=dict(width=1, color='black')))
                    for i, feature in enumerate(wide_df.columns):
                        fig_pca.add_annotation(x=loadings[i, 0]*3.5, y=loadings[i, 1]*3.5, ax=0, ay=0, text=feature, showarrow=True, arrowhead=2, arrowcolor="red")
                    st.plotly_chart(fig_pca, use_container_width=True)
            else:
                st.warning("–î–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è ‚â•3 –æ–±—ä–µ–∫—Ç–æ–≤ –∏ ‚â•2 –ø—Ä–∏–∑–Ω–∞–∫–∞.")


        # ‚îÄ‚îÄ –í–ö–õ–ê–î–ö–ê 4. –ú–ù–û–ñ–ï–°–¢–í–ï–ù–ù–´–ï –°–†–ê–í–ù–ï–ù–ò–Ø (ANOVA / KW) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        with t4:
            st.markdown("### –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (–ê–Ω–∞–ª–∏–∑ –¥–∏—Å–ø–µ—Ä—Å–∏–π –≤—Å–µ—Ö –≥—Ä—É–ø–ø –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ)")
            feature = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Ü–µ–ª–µ–≤–æ–π –ø—Ä–∏–∑–Ω–∞–∫ (–ø–µ—Ä–µ–º–µ–Ω–Ω—É—é) –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∏—Å–ø–µ—Ä—Å–∏–π:", wide_df.columns, key="anova_feat")
            
            df_stat = long_df[long_df["–ü—Ä–∏–∑–Ω–∞–∫"] == feature]
            groups = [group["–ó–Ω–∞—á–µ–Ω–∏–µ"].values for name, group in df_stat.groupby("ID")]
            group_names = [name for name, group in df_stat.groupby("ID")]
            
            valid_groups = [g for g in groups if len(g) >= 3]
            
            if len(valid_groups) < 3:
                st.error("‚ö†Ô∏è –î–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å—Ä–∞–≤–Ω–µ–Ω–∏–π –Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 3 –æ–±—ä–µ–∫—Ç–∞, –∏–º–µ—é—â–∏—Ö ‚â•3 —Ä–µ–ø–ª–∏–∫–∏. –î–ª—è –ø–∞—Ä–Ω—ã—Ö –ø–µ—Ä–µ–π–¥–∏—Ç–µ –≤–æ –≤–∫–ª–∞–¥–∫—É 'A/B –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ'.")
            else:
                st.markdown("#### 1. –û—Ü–µ–Ω–∫–∞ –¥–æ–ø—É—â–µ–Ω–∏–π (Assumptions)")
                c_assump1, c_assump2 = st.columns([1, 2])
                
                with c_assump1:
                    shapiro_p = min([stats.shapiro(g)[1] if np.var(g) > 0 else 1.0 for g in valid_groups])
                    levene_stat, levene_p = stats.levene(*valid_groups) if any(np.var(g) > 0 for g in valid_groups) else (0, 1.0)
                    
                    is_normal = shapiro_p > alpha_level
                    is_homoscedastic = levene_p > alpha_level
                    use_parametric = is_normal and is_homoscedastic
                    
                    st.write(f"**–¢–µ—Å—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç–∏ –®–∞–ø–∏—Ä–æ-–£–∏–ª–∫–∞:** p={shapiro_p:.4e} {'‚úÖ' if is_normal else '‚ùå'}")
                    st.write(f"**–¢–µ—Å—Ç –¥–∏—Å–ø–µ—Ä—Å–∏–π –õ–µ–≤–µ–Ω–∞:** p={levene_p:.4e} {'‚úÖ' if is_homoscedastic else '‚ùå'}")
                    st.info(f"üí° –ê–ª–≥–æ—Ä–∏—Ç–º –≤—ã–±—Ä–∞–ª: **{'–î–∏—Å–ø–µ—Ä—Å–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (ANOVA)' if use_parametric else '–ö—Ä–∏—Ç–µ—Ä–∏–π –ö—Ä–∞—Å–∫–µ–ª–∞ ‚Äî –£–æ–ª–ª–∏—Å–∞'}**")
                
                with c_assump2:
                    # –ì—Ä–∞—Ñ–∏–∫ –ö–≤–∞–Ω—Ç–∏–ª—å-–ö–≤–∞–Ω—Ç–∏–ª—å
                    fig_qq = go.Figure()
                    for name, group in zip(group_names, groups):
                        if len(group) >= 3 and np.var(group) > 0:
                            osm, osr = stats.probplot(group, dist="norm")[0]
                            fig_qq.add_trace(go.Scatter(x=osm, y=osr, mode='markers', name=str(name)))
                    
                    fig_qq.update_layout(title="QQ-–ì—Ä–∞—Ñ–∏–∫ (–í–∏–∑—É–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π)", 
                                         xaxis_title="–¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –∫–≤–∞–Ω—Ç–∏–ª–∏ (Norm)", yaxis_title="–≠–º–ø–∏—Ä–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è",
                                         height=300, margin=dict(t=30, b=10))
                    st.plotly_chart(fig_qq, use_container_width=True)

                st.markdown("---")
                st.markdown("#### 2. –û–±—â–∏–π —Ç–µ—Å—Ç –∏ –ê–ø–æ—Å—Ç–µ—Ä–∏–æ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (Post-Hoc)")
                if use_parametric:
                    stat, p_omnibus = stats.f_oneway(*valid_groups)
                else:
                    stat, p_omnibus = stats.kruskal(*valid_groups)
                    
                st.write(f"**p-value (–û–±—â–∏–π —Ç–µ—Å—Ç):** {p_omnibus:.4e}")
                is_significant = p_omnibus < alpha_level
                
                if is_significant:
                    st.success(f"‚úÖ –í—ã—è–≤–ª–µ–Ω—ã –∑–Ω–∞—á–∏–º—ã–µ –æ—Ç–ª–∏—á–∏—è. –ó–∞–ø—É—â–µ–Ω Post-Hoc –∞–Ω–∞–ª–∏–∑ (–ü–æ–ø—Ä–∞–≤–∫–∞ –ë–æ–Ω—Ñ–µ—Ä—Ä–æ–Ω–∏).")
                    posthoc_df = perform_pairwise_tests(df_stat, "ID", "–ó–Ω–∞—á–µ–Ω–∏–µ", parametric=use_parametric)
                    
                    ph1, ph2 = st.columns([1, 1])
                    with ph1:
                        st.dataframe(posthoc_df.style.map(
                            lambda x: 'background-color: #a8e6cf; color: black' if isinstance(x, float) and x < alpha_level else '', 
                            subset=['p_adj (Bonf)']
                        ), use_container_width=True)
                        
                    with ph2:
                        matrix = pd.DataFrame(index=group_names, columns=group_names, dtype=float)
                        for _, row in posthoc_df.iterrows():
                            matrix.loc[row['–ì—Ä—É–ø–ø–∞ 1'], row['–ì—Ä—É–ø–ø–∞ 2']] = row['p_adj (Bonf)']
                            matrix.loc[row['–ì—Ä—É–ø–ø–∞ 2'], row['–ì—Ä—É–ø–ø–∞ 1']] = row['p_adj (Bonf)']
                        np.fill_diagonal(matrix.values, 1.0)
                        
                        fig_ph = px.imshow(matrix, color_continuous_scale="Reds_r", zmin=0, zmax=alpha_level,
                                           title=f"–ú–∞—Ç—Ä–∏—Ü–∞ p-value (–ö—Ä–∞—Å–Ω—ã–º –ø–æ–¥—Å–≤–µ—á–µ–Ω—ã –æ—Ç–ª–∏—á–∏—è p < {alpha_level})")
                        st.plotly_chart(fig_ph, use_container_width=True)
                else:
                    st.warning(f"‚ö†Ô∏è –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º—ã—Ö –æ—Ç–ª–∏—á–∏–π –º–µ–∂–¥—É –≥—Ä—É–ø–ø–∞–º–∏ –≤ —Ü–µ–ª–æ–º –Ω–µ –≤—ã—è–≤–ª–µ–Ω–æ (p ‚â• {alpha_level}).")


        # ‚îÄ‚îÄ –í–ö–õ–ê–î–ö–ê 5. A/B –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï (–ü–ê–†–ê–ú–ï–¢–†–ò–ö–ê/–ù–ï–ü–ê–†–ê–ú–ï–¢–†–ò–ö–ê) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        with t5:
            st.markdown("### A/B –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (–¢–æ—á–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–≤—É—Ö –≥—Ä—É–ø–ø)")
            st.caption("–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–∞–∑–ª–∏—á–∏–π –º–µ–∂–¥—É –¥–≤—É–º—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ –≤—ã–±–æ—Ä–∫–∞–º–∏ (–ö—Ä–∏—Ç–µ—Ä–∏–π –°—Ç—å—é–¥–µ–Ω—Ç–∞, –ö—Ä–∏—Ç–µ—Ä–∏–π –ú–∞–Ω–Ω–∞-–£–∏—Ç–Ω–∏, —Ç–µ—Å—Ç –®–∞–ø–∏—Ä–æ-–£–∏–ª–∫–∞).")
            
            ab_feature = st.selectbox("1. –í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫ (–º–µ—Ç—Ä–∏–∫—É) –¥–ª—è A/B —Ç–µ—Å—Ç–∞:", wide_df.columns, key="ab_feat")
            ab_objects = st.multiselect("2. –í—ã–±–µ—Ä–∏—Ç–µ —Ä–æ–≤–Ω–æ –î–í–ê –æ–±—ä–µ–∫—Ç–∞ (–≥—Ä—É–ø–ø—ã) –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è:", wide_df.index.tolist(), max_selections=2, key="ab_objs")
            
            if len(ab_objects) == 2:
                group_A_name, group_B_name = ab_objects[0], ab_objects[1]
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ (—Ä–µ–ø–ª–∏–∫–∏) –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –≥—Ä—É–ø–ø
                group_A = long_df[(long_df["ID"] == group_A_name) & (long_df["–ü—Ä–∏–∑–Ω–∞–∫"] == ab_feature)]["–ó–Ω–∞—á–µ–Ω–∏–µ"].dropna().values
                group_B = long_df[(long_df["ID"] == group_B_name) & (long_df["–ü—Ä–∏–∑–Ω–∞–∫"] == ab_feature)]["–ó–Ω–∞—á–µ–Ω–∏–µ"].dropna().values
                
                if len(group_A) >= 3 and len(group_B) >= 3:
                    st.markdown("---")
                    
                    # –ë–õ–û–ö –ú–ï–¢–†–ò–ö
                    c_m1, c_m2, c_m3 = st.columns(3)
                    c_m1.metric(f"–°—Ä–µ–¥–Ω–µ–µ: {group_A_name}", f"{np.mean(group_A):.3f}", f"n = {len(group_A)}")
                    c_m2.metric(f"–°—Ä–µ–¥–Ω–µ–µ: {group_B_name}", f"{np.mean(group_B):.3f}", f"n = {len(group_B)}")
                    delta = np.mean(group_B) - np.mean(group_A)
                    c_m3.metric("–†–∞–∑–Ω–∏—Ü–∞ (Delta B - A)", f"{delta:.3f}")
                    
                    st.markdown("#### 1. –û—Ü–µ–Ω–∫–∞ –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç–∏ –∏ –¥–∏—Å–ø–µ—Ä—Å–∏–π (–¢–µ—Å—Ç—ã –®–∞–ø–∏—Ä–æ-–£–∏–ª–∫–∞ –∏ –õ–µ–≤–µ–Ω–∞)")
                    col_ab1, col_ab2 = st.columns(2)
                    
                    var_A, var_B = np.var(group_A), np.var(group_B)
                    
                    with col_ab1:
                        shapiro_A = stats.shapiro(group_A)[1] if var_A > 0 else 1.0
                        shapiro_B = stats.shapiro(group_B)[1] if var_B > 0 else 1.0
                        
                        st.write(f"**–®–∞–ø–∏—Ä–æ-–£–∏–ª–∫ ({group_A_name}):** p = {shapiro_A:.4f} {'‚úÖ –ù–æ—Ä–º' if shapiro_A > alpha_level else '‚ùå –ù–µ –Ω–æ—Ä–º'}")
                        st.write(f"**–®–∞–ø–∏—Ä–æ-–£–∏–ª–∫ ({group_B_name}):** p = {shapiro_B:.4f} {'‚úÖ –ù–æ—Ä–º' if shapiro_B > alpha_level else '‚ùå –ù–µ –Ω–æ—Ä–º'}")
                    
                    with col_ab2:
                        if var_A > 0 or var_B > 0:
                            levene_stat, levene_p = stats.levene(group_A, group_B)
                        else:
                            levene_p = 1.0
                        st.write(f"**–†–∞–≤–µ–Ω—Å—Ç–≤–æ –¥–∏—Å–ø–µ—Ä—Å–∏–π (–ö—Ä–∏—Ç–µ—Ä–∏–π –õ–µ–≤–µ–Ω–∞):** p = {levene_p:.4f} {'‚úÖ –†–∞–≤–Ω—ã' if levene_p > alpha_level else '‚ùå –†–∞–∑–ª–∏—á–Ω—ã'}")
                        
                    is_parametric_ab = (shapiro_A > alpha_level) and (shapiro_B > alpha_level) and (levene_p > alpha_level)
                    
                    st.markdown("#### 2. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –¢–µ—Å—Ç–æ–≤")
                    col_t1, col_t2 = st.columns(2)
                    
                    # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤
                    if var_A == 0 and var_B == 0 and np.mean(group_A) == np.mean(group_B):
                        t_p, mw_p = 1.0, 1.0
                    else:
                        _, t_p = stats.ttest_ind(group_A, group_B, equal_var=(levene_p > alpha_level))
                        _, mw_p = stats.mannwhitneyu(group_A, group_B, alternative='two-sided')
                    
                    eff_size_ab = cohens_d(group_A, group_B)
                    
                    with col_t1:
                        st.info("**–ü–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–π –∫—Ä–∏—Ç–µ—Ä–∏–π**")
                        st.metric("t-–∫—Ä–∏—Ç–µ—Ä–∏–π –°—Ç—å—é–¥–µ–Ω—Ç–∞ (p-value)", f"{t_p:.4e}")
                        if t_p < alpha_level:
                            st.success("‚úÖ –ì—Ä—É–ø–ø—ã —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ —Ä–∞–∑–ª–∏—á–∞—é—Ç—Å—è (–ø–æ t-—Ç–µ—Å—Ç—É)")
                        else:
                            st.warning("‚ö†Ô∏è –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–∞–∑–ª–∏—á–∏–π –Ω–µ—Ç (–ø–æ t-—Ç–µ—Å—Ç—É)")
                            
                    with col_t2:
                        st.info("**–ù–µ–ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–π –∫—Ä–∏—Ç–µ—Ä–∏–π**")
                        st.metric("U-–∫—Ä–∏—Ç–µ—Ä–∏–π –ú–∞–Ω–Ω–∞-–£–∏—Ç–Ω–∏ (p-value)", f"{mw_p:.4e}")
                        if mw_p < alpha_level:
                            st.success("‚úÖ –ì—Ä—É–ø–ø—ã —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ —Ä–∞–∑–ª–∏—á–∞—é—Ç—Å—è (–ø–æ –ú–∞–Ω–Ω—É-–£–∏—Ç–Ω–∏)")
                        else:
                            st.warning("‚ö†Ô∏è –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–∞–∑–ª–∏—á–∏–π –Ω–µ—Ç (–ø–æ –ú–∞–Ω–Ω—É-–£–∏—Ç–Ω–∏)")
                            
                    st.markdown(f"**–†–∞–∑–º–µ—Ä —ç—Ñ—Ñ–µ–∫—Ç–∞ (Cohen's d):** `{abs(eff_size_ab):.3f}` (–ù–∞—Å–∫–æ–ª—å–∫–æ —Ñ–∏–∑–∏—á–µ—Å–∫–∏ —Å–∏–ª—å–Ω–∞ —Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É –≤—ã–±–æ—Ä–∫–∞–º–∏)")
                    
                    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è A/B
                    st.markdown("#### 3. –í–∏–∑—É–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π")
                    ab_df = long_df[(long_df["–ü—Ä–∏–∑–Ω–∞–∫"] == ab_feature) & (long_df["ID"].isin([group_A_name, group_B_name]))]
                    fig_ab = px.histogram(ab_df, x="–ó–Ω–∞—á–µ–Ω–∏–µ", color="ID", barmode="overlay", marginal="box", 
                                          title=f"–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –∏ –ë–æ–∫—Å–ø–ª–æ—Ç: {ab_feature}", opacity=0.7)
                    st.plotly_chart(fig_ab, use_container_width=True)

                else:
                    st.warning("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –≥—Ä—É–ø–ø (–Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 3 —Ä–µ–ø–ª–∏–∫–∏ –≤ –∫–∞–∂–¥–æ–π).")
            else:
                st.info("üí° –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ —Ä–æ–≤–Ω–æ –î–í–ê –æ–±—ä–µ–∫—Ç–∞ –≤ —Å–µ–ª–µ–∫—Ç–æ—Ä–µ –≤—ã—à–µ –¥–ª—è –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.")


        # ‚îÄ‚îÄ –í–ö–õ–ê–î–ö–ê 6. –°–í–û–î–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê (TABLE) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        with t6:
            st.markdown("### –ü–æ–¥—Ä–æ–±–Ω–∞—è —Å–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –æ–±—ä–µ–∫—Ç–∞–º –∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º")
            st.caption("–†–∞—Å—Å—á–∏—Ç–∞–Ω—ã –∫–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –≤—Å–µ—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö. –ò–¥–µ–∞–ª—å–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –≤ —Å—Ç–∞—Ç—å–∏ –∏–ª–∏ –æ—Ç—á–µ—Ç—ã.")
            
            stats_summary_df = long_df.groupby(['ID', '–ü—Ä–∏–∑–Ω–∞–∫'])['–ó–Ω–∞—á–µ–Ω–∏–µ'].agg(
                –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ='count',
                –°—Ä–µ–¥–Ω–µ–µ='mean',
                –ú–µ–¥–∏–∞–Ω–∞='median',
                –ú–æ–¥–∞=calc_mode,
                –ú–∏–Ω–∏–º—É–º='min',
                –ú–∞–∫—Å–∏–º—É–º='max',
                –°—Ç_–æ—Ç–∫–ª='std',
                –î–∏—Å–ø–µ—Ä—Å–∏—è='var'
            ).reset_index()
            
            numeric_cols = ['–°—Ä–µ–¥–Ω–µ–µ', '–ú–µ–¥–∏–∞–Ω–∞', '–ú–æ–¥–∞', '–ú–∏–Ω–∏–º—É–º', '–ú–∞–∫—Å–∏–º—É–º', '–°—Ç_–æ—Ç–∫–ª', '–î–∏—Å–ø–µ—Ä—Å–∏—è']
            stats_summary_df[numeric_cols] = stats_summary_df[numeric_cols].round(4)
            
            st.dataframe(stats_summary_df, use_container_width=True, height=500)
            
            st.markdown("#### –≠–∫—Å–ø–æ—Ä—Ç —Ç–∞–±–ª–∏—Ü—ã")
            try:
                excel_data = convert_df_to_excel(stats_summary_df)
                st.download_button(
                    label="üì• –°–∫–∞—á–∞—Ç—å —Å–≤–æ–¥–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ —Ñ–æ—Ä–º–∞—Ç–µ Excel (.xlsx)",
                    data=excel_data,
                    file_name="summary_statistics.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            except Exception as e:
                st.error(f"–ú–æ–¥—É–ª—å –≤—ã–≥—Ä—É–∑–∫–∏ Excel –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –≤ –¥–∞–Ω–Ω–æ–π —Å—Ä–µ–¥–µ. –î–æ—Å—Ç—É–ø–Ω–∞ –≤—ã–≥—Ä—É–∑–∫–∞ CSV.")
                st.download_button("üì• –°–∫–∞—á–∞—Ç—å —Å–≤–æ–¥–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ CSV", convert_df_to_csv(stats_summary_df), "summary_statistics.csv", "text/csv")


        # ‚îÄ‚îÄ –í–ö–õ–ê–î–ö–ê 7. –≠–ö–°–ü–û–†–¢ –î–ê–ù–ù–´–• (VAULT) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        with t7:
            st.markdown("### –•—Ä–∞–Ω–∏–ª–∏—â–µ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏ —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
            st.caption("–ó–¥–µ—Å—å –≤—ã –º–æ–∂–µ—Ç–µ —Å–∫–∞—á–∞—Ç—å –æ—á–∏—â–µ–Ω–Ω—ã–µ –º–∞—Å—Å–∏–≤—ã –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –ø–∞—Ä—Å–∏–Ω–≥–∞.")
            
            col_v1, col_v2 = st.columns(2)
            with col_v1:
                st.markdown("**–ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ (Wide Form)**")
                st.dataframe(wide_df, use_container_width=True)
                st.download_button("üíæ –°–∫–∞—á–∞—Ç—å –º–∞—Ç—Ä–∏—Ü—É (CSV)", convert_df_to_csv_with_index(wide_df), "wide_data.csv", "text/csv")
                
            with col_v2:
                st.markdown("**–°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ (Long Form)**")
                st.dataframe(long_df, use_container_width=True)
                st.download_button("üíæ –°–∫–∞—á–∞—Ç—å —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ (CSV)", convert_df_to_csv(long_df), "long_data.csv", "text/csv")

else:
    st.info("üëà –ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∞—à –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö (—Ç–∞–±–ª–∏—Ü—É) –≤ –ø–∞–Ω–µ–ª–∏ —Å–ª–µ–≤–∞ –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã.")
    st.markdown("""
    ### üî¨ –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ StatPack OmniLab: Data Science Edition!
    –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è —Å—Ä–µ–¥–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–∞ –¥–ª—è –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω–æ–≥–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –±–µ–∑ –Ω–∞–ø–∏—Å–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –∫–æ–¥–∞ (–∞–Ω–∞–ª–æ–≥ —Å–∫—Ä–∏–ø—Ç–æ–≤ **R** –∏ –ø–∞–∫–µ—Ç–æ–≤ **SPSS / Statistica**).
    
    **–ö–ª—é—á–µ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–π –≤–µ—Ä—Å–∏–∏:**
    * ‚öñÔ∏è **A/B –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (NEW):** –í—ã–¥–µ–ª–µ–Ω–Ω–∞—è —Å—Ä–µ–¥–∞ –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –ø–æ–ø–∞—Ä–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –≤—ã–±–æ—Ä–æ–∫. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç **t-—Ç–µ—Å—Ç—ã –°—Ç—å—é–¥–µ–Ω—Ç–∞**, **U-–∫—Ä–∏—Ç–µ—Ä–∏–π –ú–∞–Ω–Ω–∞-–£–∏—Ç–Ω–∏**, —Ç–µ—Å—Ç—ã **–®–∞–ø–∏—Ä–æ-–£–∏–ª–∫–∞** –Ω–∞ –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç—å –∏ —Å—Ç—Ä–æ–∏—Ç –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—â–∏–µ—Å—è –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π.
    * üìë **–°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:** –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞—Å—á–µ—Ç —Å—Ä–µ–¥–Ω–∏—Ö, –º–µ–¥–∏–∞–Ω—ã, –º–æ–¥—ã, –º–∏–Ω–∏–º—É–º–∞/–º–∞–∫—Å–∏–º—É–º–∞, —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –∏ –¥–∏—Å–ø–µ—Ä—Å–∏–∏ —Å –≤—ã–≥—Ä—É–∑–∫–æ–π –Ω–∞–ø—Ä—è–º—É—é –≤ **Excel**.
    * üìà **–†–µ–≥—Ä–µ—Å—Å–∏—è –∏ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –ü–∏—Ä—Å–æ–Ω–∞:** –û—Ü–µ–Ω–∫–∞ –ª–∏–Ω–µ–π–Ω—ã—Ö —Å–≤—è–∑–µ–π –º–µ–∂–¥—É –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ (—Ä–∞—Å—á–µ—Ç $R^2$ –∏ p-value).
    * üß† **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≥–∏–ø–æ—Ç–µ–∑–∞:** –ü—Ä–æ–≥—Ä–∞–º–º–∞ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –¥–æ–ø—É—â–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é **QQ-–≥—Ä–∞—Ñ–∏–∫–æ–≤** –∏ —Å–∞–º–∞ –ø—Ä–æ–≤–æ–¥–∏—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ (ANOVA) –∏–ª–∏ –Ω–µ–ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ (Kruskal-Wallis) —Ç–µ—Å—Ç—ã –¥–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –≥—Ä—É–ø–ø, –¥–æ–ø–æ–ª–Ω—è—è –≤—ã–≤–æ–¥—ã —Ä–∞–∑–º–µ—Ä–æ–º —ç—Ñ—Ñ–µ–∫—Ç–∞ (Cohen's d).
    * üéª **–ò–¥–µ–∞–ª—å–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è:** –°–∫—Ä–∏–ø–∏—á–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏, –°—Ç–æ–ª–±—á–∞—Ç—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ —Å –ø–ª–∞–Ω–∫–∞–º–∏ –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç–µ–π, Heatmap, –†–∞–¥–∞—Ä—ã, PCA-Biplot –∏ –ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–µ –î–µ–Ω–¥—Ä–æ–≥—Ä–∞–º–º—ã.
    """)